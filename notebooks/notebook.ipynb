{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c8a28f-1934-45c9-8cf3-7d7afa2568d4",
   "metadata": {},
   "source": [
    "# Data Preprocessing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b42a5a8-ac37-4ed0-99f4-d09ab988581e",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eec90d4-8371-40ad-850a-0f1aa672e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dtale\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6818c63e-d4ef-446c-9efc-511e7cca416b",
   "metadata": {},
   "source": [
    "#### Importing 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae3735a1-b094-4e3e-bd8d-471fc22e20d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Region   Age   Income Online Shopper\n",
      "0   India  49.0  86400.0             No\n",
      "1  Brazil  32.0  57600.0            Yes\n",
      "2     USA  35.0  64800.0             No\n",
      "3  Brazil  43.0  73200.0             No\n",
      "4     USA  45.0      NaN            Yes\n",
      "5   India  40.0  69600.0            Yes\n",
      "6  Brazil   NaN  62400.0             No\n",
      "7   India  53.0  94800.0            Yes\n",
      "8     USA  55.0  99600.0             No\n",
      "9   India  42.0  80400.0            Yes\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('DataPreprocessing.csv')\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "dataset2 = pd.DataFrame({\n",
    "    'Region': ['France', 'Ireland', 'Germany'],\n",
    "    'Age': [21.00, 49.00, 32.0],\n",
    "    'Income': [125000.00, 80000.00, 34000.00],\n",
    "    'Online Shopper': ['Yes', 'Yes', 'No']\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "merged_dataset = pd.merge(dataset, dataset2, on='Income', how='outer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ff4a0-aea9-46ad-bd34-ac2413c2b9c2",
   "metadata": {},
   "source": [
    "### Spliting the dataset in 2 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f034e708-ede1-4f43-94a5-bcb5d01b7195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['India' 49.0 86400.0]\n",
      " ['Brazil' 32.0 57600.0]\n",
      " ['USA' 35.0 64800.0]\n",
      " ['Brazil' 43.0 73200.0]\n",
      " ['USA' 45.0 nan]\n",
      " ['India' 40.0 69600.0]\n",
      " ['Brazil' nan 62400.0]\n",
      " ['India' 53.0 94800.0]\n",
      " ['USA' 55.0 99600.0]\n",
      " ['India' 42.0 80400.0]]\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, :-1].values # without the last column\n",
    "Y = dataset.iloc[:, -1].values # just the last column\n",
    "\n",
    "#dtale.show(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1ebfbd-9ba7-47a6-b677-ee804702d2ee",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c1e97-9fbd-40e9-b343-71d488328b28",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b37a7647-889d-4df4-bccf-baef96432d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['India' 49.0 86400.0]\n",
      " ['Brazil' 32.0 57600.0]\n",
      " ['USA' 35.0 64800.0]\n",
      " ['Brazil' 43.0 73200.0]\n",
      " ['USA' 45.0 76533.33333333333]\n",
      " ['India' 40.0 69600.0]\n",
      " ['Brazil' 43.77777777777778 62400.0]\n",
      " ['India' 53.0 94800.0]\n",
      " ['USA' 55.0 99600.0]\n",
      " ['India' 42.0 80400.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer # to handle missing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "without_missing=SimpleImputer(missing_values=numpy.nan, strategy='mean') # put the average for each empty box of the table\n",
    "\n",
    "without_missing = without_missing.fit(X[:, 1:]) # concerning only the 2 last columns (first one is string)\n",
    "X[:, 1:] = without_missing.transform(X[:, 1:]) # apply these changes on the dataset \n",
    "# maybe possible to use fit_transform function, to deepen...\n",
    "    #X = fit_transform\n",
    "#dtale.show(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66814dea-bed0-4292-a5b9-99d2a4a02498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtale.show(merged_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab56006-9d96-49c8-90f3-1b7320fc3f46",
   "metadata": {},
   "source": [
    "### Encoding categorical data\n",
    "Difference between Label and OneHot : \\\n",
    "                                      - Label gives a number in int for each line (simple but the model could misunderstand the difference between numbers (priorities issues))\\\n",
    "                                      - OneHot encodes in binary columns (no hierarchy between column but a lot of columns if they are a lot of categories to label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7f1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 49.0 86400.0]\n",
      " [1.0 0.0 0.0 32.0 57600.0]\n",
      " [0.0 0.0 1.0 35.0 64800.0]\n",
      " [1.0 0.0 0.0 43.0 73200.0]\n",
      " [0.0 0.0 1.0 45.0 76533.33333333333]\n",
      " [0.0 1.0 0.0 40.0 69600.0]\n",
      " [1.0 0.0 0.0 43.77777777777778 62400.0]\n",
      " [0.0 1.0 0.0 53.0 94800.0]\n",
      " [0.0 0.0 1.0 55.0 99600.0]\n",
      " [0.0 1.0 0.0 42.0 80400.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "X_encoder = OneHotEncoder()\n",
    "\n",
    "transformer = ColumnTransformer(transformers= [('encoder', X_encoder, [0])], remainder='passthrough') #apply OneHotEncoder on the columns\n",
    "                                                                                                    # 'encoder' => name of the transformation\n",
    "                                                                                                    # [0] => transform only the first column (only the name of the country)\n",
    "                                                                                                    # remainder='passthrough' => don't modify the other columns\n",
    "X = transformer.fit_transform(X)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247dbd80",
   "metadata": {},
   "source": [
    "not necessary to use OneHotEncoder for Y because that's just Yes or No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42944b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "Y_encoder = LabelEncoder()\n",
    "Y=Y_encoder.fit_transform(Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711a831",
   "metadata": {},
   "source": [
    "### Splitting into training set and test set\n",
    "We are now splitting the dataset\n",
    "The train set that has the full data to train and the test set which has only 3 columns for testing on smaller samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf232b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 42.0 80400.0]\n",
      " [1.0 0.0 0.0 32.0 57600.0]\n",
      " [1.0 0.0 0.0 43.77777777777778 62400.0]\n",
      " [0.0 1.0 0.0 53.0 94800.0]\n",
      " [1.0 0.0 0.0 43.0 73200.0]\n",
      " [0.0 1.0 0.0 49.0 86400.0]\n",
      " [0.0 1.0 0.0 40.0 69600.0]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282304f8",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "To have the same scale between each columns (for instance, Income is way bigger than Age and the model could misinterpret it and gives more importance to the Income column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3acde582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :\n",
      "[[-0.8660254   0.8660254   0.         -0.2029809   0.44897083]\n",
      " [ 1.15470054 -1.15470054  0.         -1.82168936 -1.41706417]\n",
      " [ 1.15470054 -1.15470054  0.          0.08478949 -1.0242147 ]\n",
      " [-0.8660254   0.8660254   0.          1.5775984   1.62751925]\n",
      " [ 1.15470054 -1.15470054  0.         -0.04111006 -0.14030338]\n",
      " [-0.8660254   0.8660254   0.          0.93011502  0.94003267]\n",
      " [-0.8660254   0.8660254   0.         -0.52672259 -0.43494049]]\n",
      "\n",
      "\n",
      "X_test :\n",
      "[[-0.8660254  -1.15470054  1.         -1.33607682 -0.82778996]\n",
      " [-0.8660254  -1.15470054  1.          1.90134009  2.02036872]\n",
      " [-0.8660254  -1.15470054  1.          0.28263164  0.13250875]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train :\")\n",
    "print(X_train)\n",
    "print(\"\\n\")\n",
    "print(\"X_test :\")\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6850e2ab",
   "metadata": {},
   "source": [
    "Preparing data for LSTM DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "858a9e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6398fa00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
