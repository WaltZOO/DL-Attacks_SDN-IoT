{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e331fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5125e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Header_Length   LLC   TCP   UDP  DHCP   ARP  ICMP  IGMP   IPv  \\\n",
      "0                37.80  1.00  1.00  0.00   0.0  0.00  0.00   0.0  1.00   \n",
      "1                35.96  0.99  0.96  0.02   0.0  0.01  0.01   0.0  0.99   \n",
      "2                36.44  1.00  1.00  0.00   0.0  0.00  0.00   0.0  1.00   \n",
      "3                37.96  1.00  0.99  0.01   0.0  0.00  0.00   0.0  1.00   \n",
      "4                37.04  1.00  0.95  0.05   0.0  0.00  0.00   0.0  1.00   \n",
      "...                ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "1054080          29.60  1.00  0.90  0.10   0.0  0.00  0.00   0.0  1.00   \n",
      "1054081          32.00  1.00  1.00  0.00   0.0  0.00  0.00   0.0  1.00   \n",
      "1054082          29.60  1.00  0.90  0.10   0.0  0.00  0.00   0.0  1.00   \n",
      "1054083          32.00  1.00  1.00  0.00   0.0  0.00  0.00   0.0  1.00   \n",
      "1054084          32.00  1.00  1.00  0.00   0.0  0.00  0.00   0.0  1.00   \n",
      "\n",
      "         Tot sum  ...  fin_flag_number  syn_flag_number  rst_flag_number  \\\n",
      "0           8629  ...             0.05             0.62             0.01   \n",
      "1           9245  ...             0.04             0.64             0.05   \n",
      "2           8914  ...             0.02             0.57             0.12   \n",
      "3          10118  ...             0.06             0.67             0.03   \n",
      "4           8100  ...             0.03             0.65             0.05   \n",
      "...          ...  ...              ...              ...              ...   \n",
      "1054080    14614  ...             0.00             0.00             0.00   \n",
      "1054081    14620  ...             0.00             0.00             0.00   \n",
      "1054082    11822  ...             0.00             0.00             0.00   \n",
      "1054083    14620  ...             0.00             0.00             0.00   \n",
      "1054084     5716  ...             0.00             0.00             0.00   \n",
      "\n",
      "         psh_flag_number  ack_flag_number  cwr_flag_number  Label  cluster  \\\n",
      "0                   0.03             0.99              0.0      1        0   \n",
      "1                   0.08             0.90              0.0      1        0   \n",
      "2                   0.06             0.86              0.0      1        0   \n",
      "3                   0.06             0.96              0.0      1        0   \n",
      "4                   0.02             0.90              0.0      1        0   \n",
      "...                  ...              ...              ...    ...      ...   \n",
      "1054080             0.00             0.90              0.0      0        3   \n",
      "1054081             0.00             1.00              0.0      0        3   \n",
      "1054082             0.00             0.90              0.0      0        3   \n",
      "1054083             0.00             1.00              0.0      0        3   \n",
      "1054084             0.00             1.00              0.0      0        3   \n",
      "\n",
      "             pca1      pca2  \n",
      "0       -0.597226  0.412296  \n",
      "1       -0.555048  0.372619  \n",
      "2       -0.570778  0.336931  \n",
      "3       -0.606419  0.388384  \n",
      "4       -0.535120  0.339651  \n",
      "...           ...       ...  \n",
      "1054080 -0.173099  0.125284  \n",
      "1054081 -0.347532  0.109020  \n",
      "1054082 -0.170498  0.086994  \n",
      "1054083 -0.347538  0.109018  \n",
      "1054084 -0.349094  0.298136  \n",
      "\n",
      "[1054085 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "attacks = pd.read_csv('../datasets/CICIOT2023/tharindu_cleaned_version/nattack.csv')\n",
    "benign = pd.read_csv('../datasets/CICIOT2023/tharindu_cleaned_version/nbengin.csv')\n",
    "\n",
    "df = pd.concat([attacks, benign], ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6004478d",
   "metadata": {},
   "source": [
    "### Missing datas\n",
    "useless here because no missing datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f04aaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing datas by columns :\n",
      " Header_Length      0\n",
      "LLC                0\n",
      "TCP                0\n",
      "UDP                0\n",
      "DHCP               0\n",
      "ARP                0\n",
      "ICMP               0\n",
      "IGMP               0\n",
      "IPv                0\n",
      "Tot sum            0\n",
      "SSH                0\n",
      "Min                0\n",
      "Max                0\n",
      "AVG                0\n",
      "Std                0\n",
      "Tot size           0\n",
      "IAT                0\n",
      "Number             0\n",
      "IRC                0\n",
      "SMTP               0\n",
      "Protocol Type      0\n",
      "ece_flag_number    0\n",
      "Time_To_Live       0\n",
      "Rate               0\n",
      "fin_flag_number    0\n",
      "syn_flag_number    0\n",
      "rst_flag_number    0\n",
      "psh_flag_number    0\n",
      "ack_flag_number    0\n",
      "cwr_flag_number    0\n",
      "Label              0\n",
      "cluster            0\n",
      "pca1               0\n",
      "pca2               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer # to handle missing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"Missing datas by columns :\\n\", df.isnull().sum())\n",
    "\n",
    "#here there is no missing data so we don't have to manage this\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b5c8b",
   "metadata": {},
   "source": [
    "### Separing datas and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ceb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip() # to clean spaces on the columns names\n",
    "X = df.drop(columns=['Label']) # without labels\n",
    "Y = df['Label'] # just labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365d58c",
   "metadata": {},
   "source": [
    "### Encoding categorical data\n",
    "Difference between Label and OneHot : \\\n",
    "                                      - Label gives a number in int for each line (simple but the model could misunderstand the difference between numbers (priorities issues))\\\n",
    "                                      - OneHot encodes in binary columns (no hierarchy between column but a lot of columns if they are a lot of categories to label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "306c589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1\n",
      "1          1\n",
      "2          1\n",
      "3          1\n",
      "4          1\n",
      "          ..\n",
      "1054080    1\n",
      "1054081    1\n",
      "1054082    1\n",
      "1054083    1\n",
      "1054084    1\n",
      "Name: Label, Length: 1054085, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# no need of OneHotEncoder because all columns except Label are numerical columns\n",
    "\n",
    "Y = Y.apply(lambda x: 0 if x == 'BenignTraffic' else 1) # because we have several types of attacks and we wants bianaries Y\n",
    "\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52c71f",
   "metadata": {},
   "source": [
    "### Splitting into training set and test set\n",
    "We are now splitting the dataset\n",
    "The train set that has the full data to train and the test set which has only 3 columns for testing on smaller samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59d956c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Header_Length   LLC   TCP   UDP  DHCP   ARP  ICMP  IGMP   IPv  \\\n",
      "1008282          32.00  1.00  1.00  0.00   0.0  0.00   0.0   0.0  1.00   \n",
      "942992           29.60  1.00  0.90  0.10   0.0  0.00   0.0   0.0  1.00   \n",
      "110254           20.00  1.00  1.00  0.00   0.0  0.00   0.0   0.0  1.00   \n",
      "883848           32.00  1.00  1.00  0.00   0.0  0.00   0.0   0.0  1.00   \n",
      "506819           20.00  1.00  1.00  0.00   0.0  0.00   0.0   0.0  1.00   \n",
      "...                ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "359783           20.00  1.00  1.00  0.00   0.0  0.00   0.0   0.0  1.00   \n",
      "152315           19.76  1.00  0.98  0.02   0.0  0.00   0.0   0.0  1.00   \n",
      "963395           32.00  1.00  1.00  0.00   0.0  0.00   0.0   0.0  1.00   \n",
      "117952           20.00  1.00  1.00  0.00   0.0  0.00   0.0   0.0  1.00   \n",
      "305711           20.16  0.99  0.98  0.01   0.0  0.01   0.0   0.0  0.99   \n",
      "\n",
      "         Tot sum  ...          Rate  fin_flag_number  syn_flag_number  \\\n",
      "1008282  33001.0  ...    965.717443              0.0             0.00   \n",
      "942992     824.0  ...   1871.204104              0.0             0.00   \n",
      "110254    6000.0  ...  21478.410488              0.0             1.00   \n",
      "883848    2108.0  ...    594.388720              0.0             0.00   \n",
      "506819    6000.0  ...  27271.157347              0.0             0.85   \n",
      "...          ...  ...           ...              ...              ...   \n",
      "359783    6000.0  ...  47479.103464              0.0             1.00   \n",
      "152315    6202.0  ...  26526.081457              0.0             0.98   \n",
      "963395    2108.0  ...    750.188517              0.0             0.00   \n",
      "117952    6000.0  ...  40685.847318              0.0             1.00   \n",
      "305711    6281.0  ...   3901.061228              0.0             0.95   \n",
      "\n",
      "         rst_flag_number  psh_flag_number  ack_flag_number  cwr_flag_number  \\\n",
      "1008282             0.00             0.10             1.00              0.0   \n",
      "942992              0.00             0.00             0.90              0.0   \n",
      "110254              0.00             0.00             0.00              0.0   \n",
      "883848              0.00             0.00             1.00              0.0   \n",
      "506819              0.15             0.00             0.00              0.0   \n",
      "...                  ...              ...              ...              ...   \n",
      "359783              0.00             0.00             0.00              0.0   \n",
      "152315              0.00             0.00             0.00              0.0   \n",
      "963395              0.00             0.00             1.00              0.0   \n",
      "117952              0.00             0.00             0.00              0.0   \n",
      "305711              0.00             0.01             0.03              0.0   \n",
      "\n",
      "         cluster      pca1      pca2  \n",
      "1008282      3.0 -0.375729  0.399971  \n",
      "942992       5.0 -0.208372 -0.439170  \n",
      "110254       0.0 -0.451490 -0.280051  \n",
      "883848       5.0 -0.375158 -0.404218  \n",
      "506819       0.0 -0.429809 -0.292469  \n",
      "...          ...       ...       ...  \n",
      "359783       0.0 -0.451489 -0.280051  \n",
      "152315       0.0 -0.423260 -0.273956  \n",
      "963395       5.0 -0.374525 -0.403991  \n",
      "117952       0.0 -0.451489 -0.280051  \n",
      "305711       0.0 -0.426468 -0.242406  \n",
      "\n",
      "[737859 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9e2f1",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "To have the same scale between each columns (for instance, `Flow Duration` is way bigger than `Tot Fwd Pkts` and the model could misinterpret it and gives more importance to the Income column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ead9eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :\n",
      "          Header_Length       LLC       TCP       UDP      DHCP       ARP  \\\n",
      "1008282       1.182657  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "942992        0.779059  0.249023 -0.646594  0.892451 -0.065496 -0.249023   \n",
      "110254       -0.835334  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "883848        1.182657  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "506819       -0.835334  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "...                ...       ...       ...       ...       ...       ...   \n",
      "359783       -0.835334  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "152315       -0.875694  0.249023  0.290928 -0.200518 -0.065496 -0.249023   \n",
      "963395        1.182657  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "117952       -0.835334  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "305711       -0.808427 -0.074273  0.290928 -0.337139 -0.065496  0.074273   \n",
      "\n",
      "             ICMP      IGMP       IPv   Tot sum  ...      Rate  \\\n",
      "1008282 -0.146233 -0.034625  0.249023  5.331856  ... -0.482135   \n",
      "942992  -0.146233 -0.034625  0.249023 -1.164341  ... -0.454827   \n",
      "110254  -0.146233 -0.034625  0.249023 -0.119361  ...  0.136486   \n",
      "883848  -0.146233 -0.034625  0.249023 -0.905115  ... -0.493333   \n",
      "506819  -0.146233 -0.034625  0.249023 -0.119361  ...  0.311183   \n",
      "...           ...       ...       ...       ...  ...       ...   \n",
      "359783  -0.146233 -0.034625  0.249023 -0.119361  ...  0.920613   \n",
      "152315  -0.146233 -0.034625  0.249023 -0.078579  ...  0.288713   \n",
      "963395  -0.146233 -0.034625  0.249023 -0.905115  ... -0.488635   \n",
      "117952  -0.146233 -0.034625  0.249023 -0.119361  ...  0.715742   \n",
      "305711  -0.146233 -0.034625 -0.074273 -0.062630  ... -0.393611   \n",
      "\n",
      "         fin_flag_number  syn_flag_number  rst_flag_number  psh_flag_number  \\\n",
      "1008282        -0.234017        -1.044868        -0.131906         0.112556   \n",
      "942992         -0.234017        -1.044868        -0.131906        -0.583963   \n",
      "110254         -0.234017         0.999153        -0.131906        -0.583963   \n",
      "883848         -0.234017        -1.044868        -0.131906        -0.583963   \n",
      "506819         -0.234017         0.692550         4.790343        -0.583963   \n",
      "...                  ...              ...              ...              ...   \n",
      "359783         -0.234017         0.999153        -0.131906        -0.583963   \n",
      "152315         -0.234017         0.958273        -0.131906        -0.583963   \n",
      "963395         -0.234017        -1.044868        -0.131906        -0.583963   \n",
      "117952         -0.234017         0.999153        -0.131906        -0.583963   \n",
      "305711         -0.234017         0.896952        -0.131906        -0.514311   \n",
      "\n",
      "         ack_flag_number  cwr_flag_number   cluster      pca1      pca2  \n",
      "1008282         1.211175        -0.031878  0.948654 -0.295234  2.539793  \n",
      "942992          0.991512        -0.031878  2.056294  0.611920 -1.425018  \n",
      "110254         -0.985456        -0.031878 -0.712807 -0.705897 -0.673208  \n",
      "883848          1.211175        -0.031878  2.056294 -0.292141 -1.259876  \n",
      "506819         -0.985456        -0.031878 -0.712807 -0.588374 -0.731880  \n",
      "...                  ...              ...       ...       ...       ...  \n",
      "359783         -0.985456        -0.031878 -0.712807 -0.705891 -0.673208  \n",
      "152315         -0.985456        -0.031878 -0.712807 -0.552877 -0.644409  \n",
      "963395          1.211175        -0.031878  2.056294 -0.288709 -1.258804  \n",
      "117952         -0.985456        -0.031878 -0.712807 -0.705892 -0.673208  \n",
      "305711         -0.919557        -0.031878 -0.712807 -0.570265 -0.495341  \n",
      "\n",
      "[737859 rows x 33 columns] \n",
      "\n",
      "X_test :\n",
      "          Header_Length       LLC       TCP       UDP      DHCP       ARP  \\\n",
      "599656       -0.028137  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "976075        1.182657  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "852494        0.375461  0.249023 -1.818497  2.258662 -0.065496 -0.249023   \n",
      "609921        1.182657  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "1009804       0.106395  0.249023 -2.990399  3.624873 -0.065496 -0.249023   \n",
      "...                ...       ...       ...       ...       ...       ...   \n",
      "750712        1.182657  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "460834       -0.620081  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "424637       -0.835334  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "807808        0.375461  0.249023 -1.818497  2.258662 -0.065496 -0.249023   \n",
      "701370        1.182657  0.249023  0.525308 -0.473760 -0.065496 -0.249023   \n",
      "\n",
      "             ICMP      IGMP       IPv   Tot sum  ...      Rate  \\\n",
      "599656  -0.146233 -0.034625  0.249023  3.217266  ... -0.504449   \n",
      "976075  -0.146233 -0.034625  0.249023  1.426709  ... -0.508552   \n",
      "852494  -0.146233 -0.034625  0.249023 -1.171810  ... -0.482640   \n",
      "609921  -0.146233 -0.034625  0.249023  1.725909  ... -0.408612   \n",
      "1009804 -0.146233 -0.034625  0.249023 -1.050273  ... -0.508420   \n",
      "...           ...       ...       ...       ...  ...       ...   \n",
      "750712  -0.146233 -0.034625  0.249023  1.057251  ... -0.219871   \n",
      "460834  -0.146233 -0.034625  0.249023 -0.119361  ... -0.359337   \n",
      "424637  -0.146233 -0.034625  0.249023 -0.119361  ...  0.242699   \n",
      "807808  -0.146233 -0.034625  0.249023 -0.923285  ... -0.505146   \n",
      "701370  -0.146233 -0.034625  0.249023  2.310581  ... -0.437196   \n",
      "\n",
      "         fin_flag_number  syn_flag_number  rst_flag_number  psh_flag_number  \\\n",
      "599656         -0.234017        -1.044868        -0.131906         2.202111   \n",
      "976075         -0.234017        -1.044868        -0.131906         0.809074   \n",
      "852494         -0.234017        -1.044868         3.149593         0.809074   \n",
      "609921         -0.234017        -1.044868        -0.131906        -0.583963   \n",
      "1009804        -0.234017        -0.840466        -0.131906         2.202111   \n",
      "...                  ...              ...              ...              ...   \n",
      "750712         -0.234017        -1.044868        -0.131906         1.505592   \n",
      "460834         -0.234017         0.999153        -0.131906        -0.583963   \n",
      "424637         -0.234017         0.999153        -0.131906        -0.583963   \n",
      "807808          3.051421        -1.044868        -0.131906         2.898629   \n",
      "701370         -0.234017        -1.044868        -0.131906        -0.583963   \n",
      "\n",
      "         ack_flag_number  cwr_flag_number   cluster      pca1      pca2  \n",
      "599656          1.211175        -0.031878  0.394834 -0.067707  1.668325  \n",
      "976075          1.211175        -0.031878  0.948654 -0.131586  1.070865  \n",
      "852494          0.771849        -0.031878 -0.712807  1.871762  0.769008  \n",
      "609921          1.211175        -0.031878  0.948654 -0.029196  1.746000  \n",
      "1009804         0.332523        -0.031878 -0.712807  2.962479  0.379433  \n",
      "...                  ...              ...       ...       ...       ...  \n",
      "750712          1.211175        -0.031878  0.948654 -0.059991  1.406703  \n",
      "460834         -0.282534        -0.031878 -0.712807 -1.062155  0.235172  \n",
      "424637         -0.985456        -0.031878 -0.712807 -0.705896 -0.673208  \n",
      "807808          0.771849        -0.031878  0.394834  1.863938  1.073426  \n",
      "701370          1.211175        -0.031878  0.948654 -0.081454  1.880458  \n",
      "\n",
      "[316226 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "print(\"X_train :\\n\", X_train, \"\\n\")\n",
    "print(\"X_test :\\n\", X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943aca7",
   "metadata": {},
   "source": [
    "### Prepare data for Deep Learning (convert datas into float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6197bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "Y_train = np.array(Y_train).astype('float32')\n",
    "Y_test = np.array(Y_test).astype('float32')\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bd40d",
   "metadata": {},
   "source": [
    "### CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "243c8e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m30,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,977</span> (121.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,977\u001b[0m (121.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,977</span> (121.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,977\u001b[0m (121.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 15:46:05.601553: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 97397388 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 4.0393e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0606e-04 - val_accuracy: 1.0000 - val_loss: 0.0459\n",
      "Epoch 3/10\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9762e-04 - val_accuracy: 1.0000 - val_loss: 2.4659e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9297e-04 - val_accuracy: 1.0000 - val_loss: 3.2831e-06\n",
      "Epoch 5/10\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7883e-05 - val_accuracy: 1.0000 - val_loss: 0.1795\n",
      "Epoch 6/10\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9798e-04 - val_accuracy: 1.0000 - val_loss: 6.2505e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6392e-04 - val_accuracy: 1.0000 - val_loss: 2.2591e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1639e-05 - val_accuracy: 1.0000 - val_loss: 2.1427e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7491e-05 - val_accuracy: 1.0000 - val_loss: 3.0276e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3303e-04 - val_accuracy: 1.0000 - val_loss: 7.3122e-05\n"
     ]
    }
   ],
   "source": [
    "CNN_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)),\n",
    "    Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "CNN_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "CNN_model.summary()\n",
    "\n",
    "history = CNN_model.fit(X_train, Y_train, epochs=10, batch_size=64, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccfb46c",
   "metadata": {},
   "source": [
    "### LSTM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c66bbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,121</span> (82.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,121\u001b[0m (82.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,121</span> (82.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,121\u001b[0m (82.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 15:49:43.296607: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 97397388 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 6.8629e-06\n",
      "Epoch 2/5\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.5024e-05 - val_accuracy: 1.0000 - val_loss: 2.8048e-06\n",
      "Epoch 3/5\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.8333e-05 - val_accuracy: 1.0000 - val_loss: 3.7028e-06\n",
      "Epoch 4/5\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7180e-04 - val_accuracy: 1.0000 - val_loss: 1.1994e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m11530/11530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.6804e-05 - val_accuracy: 1.0000 - val_loss: 1.8913e-04\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "LSTM_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "LSTM_model.summary()\n",
    "\n",
    "\n",
    "history = LSTM_model.fit(X_train, Y_train, epochs=5, batch_size=64, validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7cdb8d",
   "metadata": {},
   "source": [
    "Let's save our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f296ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.save(\"cnn_ciciot_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f13083aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model.save(\"lstm_ciciot_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44b5f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9883/9883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = LSTM_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ba9b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2471/2471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 820us/step - accuracy: 1.0000 - loss: 1.6210e-05\n",
      "test loss, test acc: [7.31215623090975e-05, 0.9999936819076538]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "cnn_loaded = load_model('cnn_ciciot_model.keras')\n",
    "results = cnn_loaded.evaluate(X_test, Y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dd23989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9883/9883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 436us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00    155152\n",
      "     Attacks       1.00      1.00      1.00    161074\n",
      "\n",
      "    accuracy                           1.00    316226\n",
      "   macro avg       1.00      1.00      1.00    316226\n",
      "weighted avg       1.00      1.00      1.00    316226\n",
      "\n",
      "Confusion matrix :\n",
      " [[155152      0]\n",
      " [     2 161072]]\n",
      "Attacks detected (True Positive) : 161072\n",
      "Attacks missed (False Negative) : 2\n",
      "False alarms (False Positive) : 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred_prob = cnn_loaded.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "# (precision, recall, F1-score)\n",
    "print(classification_report(Y_test, y_pred, target_names=[\"Normal\", \"Attacks\"]))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion matrix :\\n\", cm)\n",
    "\n",
    "# Displaying the attack number\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"Attacks detected (True Positive) : {tp}\")\n",
    "print(f\"Attacks missed (False Negative) : {fn}\")\n",
    "print(f\"False alarms (False Positive) : {fp}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
